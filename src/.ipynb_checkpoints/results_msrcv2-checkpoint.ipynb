{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "st.norm.ppf(.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_metric(metrics, rounding=3):\n",
    "    metrics = np.asarray(metrics)\n",
    "    mean = metrics.mean()\n",
    "    std = np.std(metrics)\n",
    "    return (round(mean, rounding), round(std, rounding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_metric_prf(metrics):\n",
    "    n_runs = len(metrics)\n",
    "    ps=[]; rs=[]; f1s=[]\n",
    "    \n",
    "    for i in xrange(n_runs):\n",
    "        ps.append(metrics[i][0])\n",
    "        rs.append(metrics[i][1])\n",
    "        f1s.append(metrics[i][2])\n",
    "    \n",
    "    print estimate_metric(np.asarray(ps))\n",
    "    print estimate_metric(np.asarray(rs))\n",
    "    print estimate_metric(np.asarray(f1s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23tune_allmetrics.npy',\n",
       " '23alex160829034230tune_time.npy',\n",
       " '23alex160829033720tune_allmetrics.npy',\n",
       " '23alex160829033720tune_time.npy',\n",
       " '23alex160829034230tune_allmetrics.npy',\n",
       " '23OTSBR_allmetrics.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "root = 'metrics'\n",
    "files = [f for f in os.listdir(root) if isfile(join(root,f))]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_metrics = np.load('metrics/23OTSBR_allmetrics.npy')\n",
    "hammings = []\n",
    "one_errors = []\n",
    "coverages = []\n",
    "rank_losses = []\n",
    "micros = []\n",
    "macros = []\n",
    "lrap = []\n",
    "\n",
    "for metrics in all_metrics:\n",
    "    hammings.append(metrics[0])\n",
    "    one_errors.append(metrics[1])\n",
    "    coverages.append(metrics[2])\n",
    "    rank_losses.append(metrics[3])\n",
    "    micros.append(metrics[4])\n",
    "    macros.append(metrics[5])\n",
    "    lrap.append(metrics[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex=r\"^metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded metrics19\n",
      "loaded metrics13\n",
      "loaded metrics25\n",
      "loaded metrics9\n",
      "loaded metrics21\n",
      "loaded metrics1\n",
      "loaded metrics28\n",
      "loaded metrics3\n",
      "loaded metrics0\n",
      "loaded metrics12\n",
      "loaded metrics26\n",
      "loaded metrics29\n",
      "loaded metrics4\n",
      "loaded metrics17\n",
      "loaded metrics7\n",
      "loaded metrics22\n",
      "loaded metrics8\n",
      "loaded metrics2\n",
      "loaded metrics15\n",
      "loaded metrics24\n",
      "loaded metrics16\n",
      "loaded metrics6\n",
      "loaded metrics11\n",
      "loaded metrics5\n",
      "loaded metrics23\n",
      "loaded metrics14\n",
      "loaded metrics18\n",
      "loaded metrics20\n",
      "loaded metrics10\n",
      "loaded metrics27\n",
      "Results for 30 runs\n"
     ]
    }
   ],
   "source": [
    "hammings = []\n",
    "one_errors = []\n",
    "coverages = []\n",
    "rank_losses = []\n",
    "micros = []\n",
    "macros = []\n",
    "labels = []\n",
    "\n",
    "for single_file in files:\n",
    "    try:\n",
    "        if re.search(regex, single_file): \n",
    "            with open(join(root,single_file)) as f:\n",
    "                try: \n",
    "                    hamming = pickle.load(f)\n",
    "                    one_error = pickle.load(f)\n",
    "                    coverage = pickle.load(f)\n",
    "                    rank_loss = pickle.load(f)\n",
    "                    micro = pickle.load(f)\n",
    "                    macro = pickle.load(f)\n",
    "#                     label = pickle.load(f)\n",
    "                    print 'loaded',single_file\n",
    "\n",
    "                    hammings.append(hamming)\n",
    "                    one_errors.append(one_error)\n",
    "                    coverages.append(coverage)\n",
    "                    rank_losses.append(rank_loss)\n",
    "                    micros.append(micro)\n",
    "                    macros.append(macro)\n",
    "#                     labels.append(label)\n",
    "                except EOFError:\n",
    "                    print 'broken file',single_file\n",
    "                    pass\n",
    "    except IOError:\n",
    "        break\n",
    "    \n",
    "    \n",
    "print 'Results for',len(hammings),'runs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss (0.046, 0.003)\n",
      "One-error (0.596, 0.028)\n",
      "Coverage (11.502, 0.748)\n",
      "Rank loss (0.255, 0.021)\n",
      "Micro\n",
      "(0.822, 0.018)\n",
      "(0.737, 0.021)\n",
      "(0.777, 0.013)\n",
      "None\n",
      "Macro\n",
      "(0.818, 0.018)\n",
      "(0.697, 0.025)\n",
      "(0.74, 0.021)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print 'Hamming loss',estimate_metric(hammings)\n",
    "print 'One-error',estimate_metric(one_errors)\n",
    "print 'Coverage',estimate_metric(coverages)\n",
    "print 'Rank loss',estimate_metric(rank_losses)\n",
    "\n",
    "print 'Micro\\n',estimate_metric_prf(micros)\n",
    "print 'Macro\\n',estimate_metric_prf(macros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
